{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# Challenge : predict conversions üèÜüèÜ\n",
    "\n",
    "This is the template that shows the different steps of the challenge. In this notebook, all the training/predictions steps are implemented for a very basic model (logistic regression with only one variable). Please use this template and feel free to change the preprocessing/training steps to get the model with the best f1-score ! May the force be with you üß®üß®  \n",
    "\n",
    "**For a detailed description of this project, please refer to *02-Conversion_rate_challenge.ipynb*.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "# Read file with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.head()\n",
    "data.describe()\n",
    "data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Il n'y a pas de valeurs manquantes : pas besoin d'imputation\n",
    "* Pas besoin de label encoder\n",
    "* new_user, country, source est cat√©gorielle : mais pas besoin d'encoder\n",
    "* age et pages visit√©es sont quantitatives : on doit les normaliser\n",
    "* ATTENTION : outliers dans Age : 123 ans ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrer que les ages < 90\n",
    "data = data[data['age'] < 90]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM0feCss5sLZ"
   },
   "source": [
    "# The dataset is quite big : you must create a sample of the dataset before making any visualizations !\n",
    "data_sample = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize pairwise dependencies before taking out outliers\n",
    "fig = px.scatter_matrix(data_sample)\n",
    "fig.update_layout(\n",
    "        title = go.layout.Title(text = \"Bivariate analysis\", x = 0.5), showlegend = False, \n",
    "            autosize=False, height=800, width = 800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kaleido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "# Preprocessing \n",
    "classification model as Y (target = conversion) is categorical ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjEHMGoY3kMB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['country', 'age', 'new_user', 'source', 'total_pages_visited'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# d√©finition features :\n",
    "\n",
    "features_list = ['country', 'age', 'new_user', 'source', 'total_pages_visited']\n",
    "target_variable = 'converted'\n",
    "\n",
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in ['age', 'new_user', 'total_pages_visited'] :\n",
    "  X[feature + \"_2\"] = X[feature].apply(lambda x : x**2)\n",
    "  X[feature + \"_3\"] = X[feature].apply(lambda x : x**3)\n",
    "  X[feature + \"_4\"] = X[feature].apply(lambda x : x**4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0, stratify = Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "Preprocessing done\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "num_featureencoder = StandardScaler()\n",
    "num_features = ['age', 'total_pages_visited']\n",
    "\n",
    "cat_featureencoder = OneHotEncoder(drop='first')\n",
    "cat_features = ['country', 'new_user', 'source']\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_featureencoder, num_features),\n",
    "        ('cat', cat_featureencoder, cat_features)\n",
    "    ])\n",
    "\n",
    "print(\"Preprocessing done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "...Done.\n",
      "[[-1.51987065 -0.26099836  0.          0.          1.          0.\n",
      "   0.          1.        ]\n",
      " [ 2.2307148   0.03829244  0.          0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 1.86775492 -0.56028917  0.          0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [-1.51987065 -1.15887077  0.          0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [-1.03592414  0.33758325  0.          0.          1.          1.\n",
      "   0.          0.        ]]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Performing preprocessings on test set...\n",
      "...Done\n",
      "[[-0.79395089  2.73190968  0.          0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.53690202  0.03829244  0.          0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [-0.18901775 -0.26099836  0.          0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.0529555   0.93616485  0.          0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [-0.67296426  0.93616485  0.          0.          0.          1.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5]) # MUST use this syntax because X_train is a numpy array and not a pandas DataFrame anymore\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b_aU7ij7K3Q"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "#c = PassiveAggressiveClassifier()\n",
    "#c = Perceptron()\n",
    "# = RidgeClassifierCV()\n",
    "c =  SGDClassifier(alpha = 0.0001)\n",
    "#c5 = SCGOneClassSVM()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cross validation pour avoir une incertitude\n",
    "scores = cross_val_score(classifier, X_train, Y_train, scoring = \"f1\", cv=5)\n",
    "print('The cross-validated is : ', scores.mean())\n",
    "print('The standard deviation is : ', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "parameters = [{'solver': ['lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "              {'penalty':['l1', 'l2']},\n",
    "              {'C':[1, 3, 5, 6, 10, 100]}]\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 5,\n",
    "                           verbose=0)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1qhidLbq7o-5",
    "outputId": "6bfb746c-1ff4-41c9-b0d6-a98fd09a444d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'alpha': 0.0001}\n",
      "Best validation accuracy gini:  0.985405278775574\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "### Grid of values for decision tree to be tested\n",
    "params = {\n",
    "    'alpha'  : [0.00001, 0.0001]\n",
    "}\n",
    "gridsearch = GridSearchCV(c, param_grid = params, cv = 5) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy gini: \", gridsearch.best_score_)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= gridsearch.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions et r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Au2TK_vw7rD-",
    "outputId": "702789a8-4631-4c29-f297-e4b2901f3195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "f1-score on train set :  0.7615017798374638\n",
      "f1-score on test set :  0.7667269439421338\n",
      "f1-score on entire set :  0.7695624308104645\n"
     ]
    }
   ],
   "source": [
    "c.fit(X_train, Y_train)\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = c.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = c.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()\n",
    "\n",
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "X_total = np.append(X_train,X_test,axis=0)\n",
    "Y_total = np.append(Y_train,Y_test)\n",
    "\n",
    "c.fit(X_total,Y_total)\n",
    "print(\"Predictions on test set...\")\n",
    "Y_total_pred = c.predict(X_total)\n",
    "print(\"...Done.\")\n",
    "\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print(\"f1-score on entire set : \", f1_score(Y_total, Y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.7615017798374638\n",
      "f1-score on test set :  0.7667269439421338\n",
      "f1-score on entire set :  0.7695624308104645\n"
     ]
    }
   ],
   "source": [
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print(\"f1-score on entire set : \", f1_score(Y_total, Y_total_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxJCTlz0_2it"
   },
   "source": [
    "## Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6x7p1nyr_3UV",
    "outputId": "8e5b91ba-ca06-4486-d808-37a6aaaa8cf7",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print('The cross-validated is : ', scores.mean())\n",
    "print('The standard deviation is : ', scores.std())\n",
    "print('Value should be between :', round(scores.mean()-scores.std(), 3), \"and\", round(scores.mean()+scores.std(), 3))\n",
    "print('')\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print(\"f1-score on entire set : \", f1_score(Y_total, Y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print(\"f1-score on entire set : \", f1_score(Y_total, Y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "KhDTCeBy__JK",
    "outputId": "72c82d66-d765-437e-e9ef-4ccc80e7183f",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize confusion matrices\n",
    "_ , ax = plt.subplots() # Get subplot from matplotlib\n",
    "ax.set(title=\"Confusion Matrix on Train set\") # Set a title that we will add into ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(classifier, X_train, Y_train, ax=ax) # ConfusionMatrixDisplay from sklearn\n",
    "plt.show()\n",
    "\n",
    "_ , ax = plt.subplots() # Get subplot from matplotlib\n",
    "ax.set(title=\"Confusion Matrix on Test set\") # Set a title that we will add into ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(classifier, X_test, Y_test, ax=ax) # ConfusionMatrixDisplay from sklearn\n",
    "plt.show()\n",
    "\n",
    "_ , ax = plt.subplots() # Get subplot from matplotlib\n",
    "ax.set(title=\"Confusion Matrix on entire set\") # Set a title that we will add into ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(classifier, X_total, Y_total, ax=ax) # ConfusionMatrixDisplay from sklearn\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Report on Train set : \\n\" + classification_report(Y_train, Y_train_pred))\n",
    "print(\"Report on Train set : \\n\" + classification_report(Y_test, Y_test_pred))\n",
    "print(\"Report on Train set : \\n\" + classification_report(Y_total, Y_total_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©dictions sur TEST set + √©criture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tr4CEaPzzbP-",
    "outputId": "f0d1c8ed-be4b-4974-d7b9-f23a49344d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "features_list = ['country', 'age', 'new_user', 'source', 'total_pages_visited']\n",
    "X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "#print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "#X_without_labels = X_without_labels.values\n",
    "#print(\"...Done\")\n",
    "\n",
    "# print(X_without_labels[0:5,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in ['age', 'new_user', 'total_pages_visited'] :\n",
    "  X_without_labels[feature + \"_2\"] = X_without_labels[feature].apply(lambda x : x**2)\n",
    "  X_without_labels[feature + \"_3\"] = X_without_labels[feature].apply(lambda x : x**3)\n",
    "  X_without_labels[feature + \"_4\"] = X_without_labels[feature].apply(lambda x : x**4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "LoUISfsT0HMR",
    "outputId": "e42dc389-5e77-4e13-ccbc-1fef4aa2c0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[-0.31000438  3.33049128  0.          1.          0.          0.\n",
      "   0.          1.        ]\n",
      " [-1.03592414  0.03829244  0.          1.          0.          1.\n",
      "   1.          0.        ]\n",
      " [ 0.17394213 -1.15887077  0.          0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [ 0.17394213  0.33758325  0.          0.          1.          1.\n",
      "   0.          0.        ]\n",
      " [-0.67296426 -0.56028917  0.          0.          0.          0.\n",
      "   0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# CHECK YOU ARE USING X_without_labels\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_without_labels = preprocessor.transform(X_without_labels)\n",
    "print(\"...Done\")\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 21:52\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(now.strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuWSEHuwEQJ"
   },
   "outputs": [],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "data_end = {\n",
    "    'converted': c.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data_end)\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_CTang-model26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
